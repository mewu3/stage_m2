Building DAG of jobs...
Using shell: /bin/bash
Provided cores: 12
Rules claiming more threads will be scaled down.
Conda environments: ignored
Job counts:
	count	jobs
	1	all
	1	splitFiles
	2
Select jobs to execute...

[Tue Mar 16 17:07:06 2021]
checkpoint splitFiles:
    input: /datater/wu/data_test/msa/zika.msa
    output: /datater/wu/data_test/zika/splitFiles
    jobid: 3
Downstream jobs will be updated after completion.

Updating job all.
InputFunctionException in line 56 of /datater/wu/stage_m2_merge/Snakefile:
Error:
  AttributeError: 'Wildcards' object has no attribute 'sample'
Wildcards:

Traceback:
  File "/datater/wu/stage_m2_merge/Snakefile", line 47, in aggregate_forwardInput
Removing output files of failed job splitFiles since they might be corrupted:
/datater/wu/data_test/zika/splitFiles
Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
Complete log: /datater/wu/stage_m2_merge/.snakemake/log/2021-03-16T170705.529350.snakemake.log
