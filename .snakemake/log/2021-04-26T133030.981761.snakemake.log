Building DAG of jobs...
Using shell: /bin/bash
Provided cores: 12
Rules claiming more threads will be scaled down.
Conda environments: ignored
Job counts:
	count	jobs
	1	MSA
	1	all
	1	checkHeterodimer
	1	evaluation2
	1	getKmerPosition2
	1	getKmerPosition3
	1	getKmerPosition4
	7
Select jobs to execute...

[Mon Apr 26 13:30:31 2021]
rule MSA:
    input: /datater/wu/data/MSSPE-variant/coronavirus/coronavirus0.99.uniq
    output: /datater/wu/data/MSSPE-variant/coronavirus/coronavirus0.99.msa
    log: /datater/wu/data/MSSPE-variant/coronavirus/log/mafft.log
    jobid: 12
    wildcards: sample=coronavirus

Terminating processes on user request, this might take some time.
[Mon Apr 26 13:30:54 2021]
Error in rule MSA:
    jobid: 12
    output: /datater/wu/data/MSSPE-variant/coronavirus/coronavirus0.99.msa
    log: /datater/wu/data/MSSPE-variant/coronavirus/log/mafft.log (check log file(s) for error message)
    shell:
        mafft --auto         --thread -1         --op 1.53         --ep 0.123         --bl 62         --jtt 62         --tm 62                           --inputorder                                    /datater/wu/data/MSSPE-variant/coronavirus/coronavirus0.99.uniq > /datater/wu/data/MSSPE-variant/coronavirus/coronavirus0.99.msa         2> /datater/wu/data/MSSPE-variant/coronavirus/log/mafft.log
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)

Removing output files of failed job MSA since they might be corrupted:
/datater/wu/data/MSSPE-variant/coronavirus/coronavirus0.99.msa
Complete log: /datater/wu/MSSPE/.snakemake/log/2021-04-26T133030.981761.snakemake.log
