Building DAG of jobs...
Using shell: /bin/bash
Provided cores: 12
Rules claiming more threads will be scaled down.
Conda environments: ignored
Job counts:
	count	jobs
	1	aggregate_allReverseOligo
	1	all
	1	reverse_filtering
	1	splitFiles
	4
Select jobs to execute...

[Thu Mar 25 15:12:00 2021]
checkpoint splitFiles:
    input: /datater/wu/data/enterovirus/enterovirus.msa
    output: /datater/wu/data/enterovirus/splitFiles
    jobid: 3
    wildcards: sample=enterovirus
Downstream jobs will be updated after completion.

Updating job aggregate_allReverseOligo.
MissingInputException in line 1 of /datater/wu/stage_m2/rules/reverse_kmer_dsk.smk:
Missing input files for rule dskReverse:
/datater/wu/data/enterovirus/splitFiles/reverse5842-6346.nessieOut/datater/wu/data/enterovirus/splitFiles/reverse5842-6346.LC.fasta
Removing output files of failed job splitFiles since they might be corrupted:
/datater/wu/data/enterovirus/splitFiles
Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
Complete log: /datater/wu/stage_m2/.snakemake/log/2021-03-25T151200.197716.snakemake.log
