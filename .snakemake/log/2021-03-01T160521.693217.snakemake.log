Building DAG of jobs...
Using shell: /bin/bash
Provided cores: 8
Rules claiming more threads will be scaled down.
Conda environments: ignored
Job counts:
	count	jobs
	1	all
	1	dsk
	2
Select jobs to execute...

[Mon Mar  1 16:05:22 2021]
rule dsk:
    input: /datater/wu/data/splitFiles
    output: /datater/wu/data/kmerCounting/enterovirus.forward.fasta (dynamic)
    jobid: 4
    wildcards: sample=enterovirus

Subsequent jobs will be added dynamically depending on the output of this job
Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
Complete log: /datater/wu/stage_m2/.snakemake/log/2021-03-01T160521.693217.snakemake.log
