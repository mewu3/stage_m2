Building DAG of jobs...
Using shell: /bin/bash
Provided cores: 12
Rules claiming more threads will be scaled down.
Conda environments: ignored
Job counts:
	count	jobs
	1	aggregate_allReverseOligo
	1	all
	1	allToFasta
	1	mafft
	1	reverse_filtering
	1	splitFiles
	6
Select jobs to execute...

[Wed Mar 17 11:05:02 2021]
rule mafft:
    input: /datater/wu/data/zika/zika.uniq
    output: /datater/wu/data/zika/zika.msa
    log: /datater/wu/data/zika/log/mafft.log
    jobid: 5
    wildcards: sample=zika

[Wed Mar 17 11:05:02 2021]
Finished job 5.
1 of 6 steps (17%) done
Select jobs to execute...

[Wed Mar 17 11:05:02 2021]
checkpoint splitFiles:
    input: /datater/wu/data/zika/zika.msa
    output: /datater/wu/data/zika/splitFiles
    jobid: 4
    wildcards: sample=zika
Downstream jobs will be updated after completion.

Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
Complete log: /datater/wu/stage_m2/.snakemake/log/2021-03-17T110501.922555.snakemake.log
