Building DAG of jobs...
Using shell: /bin/bash
Provided cores: 12
Rules claiming more threads will be scaled down.
Conda environments: ignored
Job counts:
	count	jobs
	1	all
	1	clustering
	2
Select jobs to execute...

[Thu May  6 13:43:12 2021]
rule clustering:
    input: /datater/wu/data/tmp/sars2Complet.uniq.fasta
    output: /datater/wu/data/tmp/sars2Complet.uniq.cls95.fasta
    jobid: 2

Terminating processes on user request, this might take some time.
[Thu May  6 13:53:02 2021]
Error in rule clustering:
    jobid: 2
    output: /datater/wu/data/tmp/sars2Complet.uniq.cls95.fasta
    shell:
        
        lib/cdhit/psi-cd-hit//psi-cd-hit.pl -i /datater/wu/data/tmp/sars2Complet.uniq.fasta -o /datater/wu/data/tmp/sars2Complet.uniq.cls95.fasta         -c 0.95 -G 1 -g 1 -prog blastn -circle 1         -exec local -para 8 -blp 4
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)

Complete log: /datater/wu/MSSPE/.snakemake/log/2021-05-06T134312.274147.snakemake.log
