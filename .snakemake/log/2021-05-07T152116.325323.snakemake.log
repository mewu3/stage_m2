Building DAG of jobs...
Using shell: /bin/bash
Provided cores: 1 (use --cores to define parallelism)
Rules claiming more threads will be scaled down.
Conda environments: ignored
Job counts:
	count	jobs
	1	all
	8	test5
	9
Select jobs to execute...

[Fri May  7 15:21:17 2021]
rule test5:
    input: /datater/wu/data/tmp/MSSPE-basic_coronavirusCuratedWithoutSarsCov2_kmer13_stritMatch.bowtie, /datater/wu/data/tmp/MSSPE-basic_coronavirusCuratedWithoutSarsCov2_kmer13_notstritMatch.bowtie, /datater/wu/data/tmp/sars2_variants.uniq.fasta
    output: /datater/wu/data/tmp/MSSPE-basic_coronavirusCuratedWithoutSarsCov2_kmer13_stritMatch_statistic.out, /datater/wu/data/tmp/MSSPE-basic_coronavirusCuratedWithoutSarsCov2_kmer13_notstritMatch_statistic.out
    jobid: 34
    wildcards: datadir=MSSPE-basic, sample=coronavirusCuratedWithoutSarsCov2, kmerSize=kmer13

Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
Complete log: /datater/wu/MSSPE/.snakemake/log/2021-05-07T152116.325323.snakemake.log
