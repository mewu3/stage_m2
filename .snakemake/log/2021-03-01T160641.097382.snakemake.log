Building DAG of jobs...
Using shell: /bin/bash
Provided cores: 12
Rules claiming more threads will be scaled down.
Conda environments: ignored
Job counts:
	count	jobs
	1	all
	1	dsk
	2
Select jobs to execute...

[Mon Mar  1 16:06:41 2021]
rule dsk:
    input: /datater/wu/data/splitFiles
    output: /datater/wu/data/kmerCounting/enterovirus.forward.fasta
    jobid: 4
    wildcards: sample=enterovirus

Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
Complete log: /datater/wu/stage_m2/.snakemake/log/2021-03-01T160641.097382.snakemake.log
