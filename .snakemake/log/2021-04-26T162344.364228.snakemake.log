Building DAG of jobs...
Updating job filtering2.
Updating job filtering2.
Using shell: /bin/bash
Provided cores: 12
Rules claiming more threads will be scaled down.
Conda environments: ignored
Job counts:
	count	jobs
	1	all
	2	generateWebPage
	3
Select jobs to execute...

[Mon Apr 26 16:23:45 2021]
rule generateWebPage:
    input: /datater/wu/data/MSSPE-basic/zika/kmer13/allOligo.set, /datater/wu/data/MSSPE-basic/zika/zika.msa
    output: /datater/wu/data/MSSPE-basic/zika/kmer13/evaluation/report.html, /datater/wu/data/MSSPE-basic/zika/kmer13/evaluation/style.css
    jobid: 27
    wildcards: sample=zika

[Mon Apr 26 16:23:45 2021]
rule generateWebPage:
    input: /datater/wu/data/MSSPE-basic/enterovirus/kmer13/allOligo.set, /datater/wu/data/MSSPE-basic/enterovirus/enterovirus.msa
    output: /datater/wu/data/MSSPE-basic/enterovirus/kmer13/evaluation/report.html, /datater/wu/data/MSSPE-basic/enterovirus/kmer13/evaluation/style.css
    jobid: 26
    wildcards: sample=enterovirus

Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
Complete log: /datater/wu/MSSPE/.snakemake/log/2021-04-26T162344.364228.snakemake.log
