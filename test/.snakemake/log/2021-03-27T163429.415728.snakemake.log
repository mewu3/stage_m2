Building DAG of jobs...
Using shell: /bin/bash
Provided cores: 12
Rules claiming more threads will be scaled down.
Job counts:
	count	jobs
	1	all
	2	test
	3
Select jobs to execute...

[Sat Mar 27 16:34:29 2021]
rule test:
    input: /datater/wu/stage_m2/test/reverse0-501.fasta
    output: /datater/wu/stage_m2/test/reverse0-501.out
    jobid: 1
    wildcards: seg=0-501


[Sat Mar 27 16:34:29 2021]
rule test:
    input: /datater/wu/stage_m2/test/reverse0-504.fasta
    output: /datater/wu/stage_m2/test/reverse0-504.out
    jobid: 2
    wildcards: seg=0-504

[Sat Mar 27 16:34:31 2021]
Error in rule test:
    jobid: 1
    output: /datater/wu/stage_m2/test/reverse0-501.out
    shell:
        python3 kmerSelect_iterac.py /datater/wu/stage_m2/test/reverse0-501.fasta /datater/wu/stage_m2/test/reverse0-501.out
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)

Removing output files of failed job test since they might be corrupted:
/datater/wu/stage_m2/test/reverse0-501.out
[Sat Mar 27 16:34:38 2021]
Finished job 2.
1 of 3 steps (33%) done
Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
Complete log: /datater/wu/stage_m2/test/.snakemake/log/2021-03-27T163429.415728.snakemake.log
